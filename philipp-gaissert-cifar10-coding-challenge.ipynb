{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook contains the code for a classifier on the CIFAR-10 dataset.\n",
    "# The classifier is a convolutional neural network built primarily using tools from the PyTorch library.\n",
    "#\n",
    "# I have organized this notebook as follows:\n",
    "#\n",
    "# PREPARATION CELL 1: Importing libraries and packages\n",
    "# PREPARATION CELL 2: Transformation chain for converting the CIFAR-10 dataset\n",
    "# PREPARATION CELL 3: Downloading and converting the CIFAR-10 dataset\n",
    "# PREPARATION CELL 4: Iterators for loading images from the training and test sets\n",
    "# PREPARATION CELL 5: Convolution neural network architecture\n",
    "# PREPARATION CELL 6: Loss and optimization functions\n",
    "#    TRAINING CELL  : Training the network on the CIFAR-10 training set\n",
    "#     TESTING CELL 1: Matching test images one batch at a time\n",
    "#     TESTING CELL 2: Computing the network's overall matching accuracy\n",
    "#     Testing CELL 3: Computing the network's per-class matching accuracy\n",
    "#\n",
    "# The notebook is organized so that the training session occurs after the necessary\n",
    "# preparations have been executed and is followed by three separate tests that each measure\n",
    "# the trained network's accuracy.\n",
    "# I have provided commentary throughout this notebook, and I would be happy to discuss my approach\n",
    "# to this assignment further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREPARATION CELL 1\n",
    "## Imports all libraries and packages used in this notebook\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREPARATION CELL 2\n",
    "## Prepares a chain of transformations to convert the CIFAR-10 dataset into tensors of normalized values\n",
    "\n",
    "cifar10transform = transforms.Compose(\n",
    "    \n",
    "            [\n",
    "                # Transformation 1:\n",
    "                # Convert PIL image data with shape (Height x Width x Channel) and integer values [0, 255] \n",
    "                # into tensors with shape (Channel x Height x Width) and float values [0.0, 1.0]\n",
    "                transforms.ToTensor(),\n",
    "                \n",
    "                # Transformation 2:\n",
    "                # Normalize the values of the converted CIFAR-10 dataset \n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ]\n",
    ")\n",
    "\n",
    "# Additional comments:\n",
    "# The means and standard deviations I used for normalization were found online.\n",
    "# I used these values again for the unnormalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREPARATION CELL 3\n",
    "## Downloads and converts the training and test sets of the CIFAR-10 dataset for use in the Convolution Neural Network\n",
    "\n",
    "# Both sets are saved in a folder 'data' in the notebook's directory\n",
    "  # (is there a way to create a folder in the directory from within a notebook using Python?)\n",
    "\n",
    "# Downloads, transforms, and stores the CIFAR-10 training set\n",
    "trainingset = CIFAR10(root='./data', train=True, download=True, transform=cifar10transform)\n",
    "\n",
    "# Downloads, transforms, and stores the CIFAR-10 test set\n",
    "testset = CIFAR10(root='./data', train=False, download=True, transform=cifar10transform)\n",
    "\n",
    "# Defines a list of the 10 classes of images in the CIFAR-10 dataset, indexed 0-9\n",
    "# airplane (0), automobile (1), bird (2), cat (3), deer (4), dog (5), frog (6), horse (7), ship (8), truck (9)\n",
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Additional comments:\n",
    "# Later on in the training and testing sections, the term 'labels' becomes somewhat interchangeable with the indices \n",
    "# of the classes of images in the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREPARATION CELL 4\n",
    "## Prepares iterators for the training and test datasets\n",
    "\n",
    "# Defines an iterator that returns images from the training set in randomly selected batches of 4, w/o replacement\n",
    "# Will feed images to the network during training\n",
    "trainingloader = DataLoader(trainingset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Defines an iterator that returns images from the test set in randomly selected batches of 4, w/o replacement\n",
    "# Will feed images to the network during testing, following training\n",
    "testloader = DataLoader(testset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Additional comments:\n",
    "# I tested out larger batch sizes (8 and 10), but those both led to a consistent reduction in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREPARATION CELL 5\n",
    "## Prepares the architecture of the convolutional neural network\n",
    "\n",
    "# Defines a subclass of networks called 'CNN', based on the torch.nn.Module class\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    # Defines the network's building blocks within the 'CNN' class's constructor\n",
    "    # 3 convolutional layers, 3 max pooling layers (identical), 3 fully-connected layers\n",
    "    # Not included here: flatten layer (x.view below), rectified linear unit activation (F.relu below)\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(CNN, self).__init__()                      \n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)      # Convolution 1:  3-channel input -> 16-channel output\n",
    "                                                         #                 3x3 filter, stride: 1, zero-padding: 1   \n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)     # Convolution 2: 16-channel input -> 32-channel output\n",
    "                                                         #                 3x3 filter, stride: 1, zero-padding: 1 \n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)     # Convolution 3: 32-channel input -> 64-channel output\n",
    "                                                         #                 3x3 filter, stride: 1. zero-padding: 1\n",
    "        self.pool = nn.MaxPool2d(2, 2)                   # 2D Max Pooling 1,2,3: 2x2 window, stride: 2\n",
    "                                                         #\n",
    "        self.fc1 = nn.Linear(64*4*4, 512)                # Fully-Connected 1: 1024-width input -> 512-width output\n",
    "        self.fc2 = nn.Linear(512, 256)                   # Fully-Connected 2:  512-width input -> 256-width output\n",
    "        self.fc3 = nn.Linear(256, 10)                    # Fully-Connected 3:  512-width input ->  10-width output\n",
    "        \n",
    "    # Defines the sequence of the network's algorithm within the 'CNN' class's forward function\n",
    "    # The full sequence is mapped out below to the right\n",
    "    def forward(self, x):                                \n",
    "                                                         #    INPUT (3x32x32 image data)\n",
    "        x = self.pool(F.relu(self.conv1(x)))             # -> Convolution 1 -> ReLU activation -> 2D Max Pooling 1\n",
    "        x = self.pool(F.relu(self.conv2(x)))             # -> Convolution 2 -> ReLU activation -> 2D Max Pooling 2\n",
    "        x = self.pool(F.relu(self.conv3(x)))             # -> Convolution 3 -> ReLU activation -> 2D Max Pooling 3\n",
    "        x = x.view(-1, 64*4*4)                           # -> Flatten/Reshape\n",
    "        x = F.relu(self.fc1(x))                          # -> Fully-Connected 1 -> ReLU activation\n",
    "        x = F.relu(self.fc2(x))                          # -> Fully-Connected 2 -> ReLU activation\n",
    "        x = self.fc3(x)                                  # -> Fully-Connected 3\n",
    "        return x                                         # -> OUTPUT (1x10 probability tensor)\n",
    "\n",
    "# Defines an object of the 'CNN' class that will serve as our convolutional neural network\n",
    "cnn = CNN()\n",
    "\n",
    "# Additional comments:\n",
    "# Having a filter-size of 3, stride of 1, and zero-padding of 1 means that the outputs of the convolution layers\n",
    "# will have the same dimensions as their inputs.\n",
    "# Having a window-size of 2 and stride of 2 means that the outputs of the max pooling layers will have dimensions that\n",
    "# are half the size of the dimensions of their inputs.\n",
    "# For these reasons, the input for the first fully-connected layer will be 64x4x4. The dimensions of the original\n",
    "# channels (32x32) are halved three times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREPARATION CELL 6\n",
    "## Prepares the tools for computing and reducing the network's error\n",
    "\n",
    "# Defines a loss function that computes cross-entropy loss, a common measure of performance for classification networks\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Defines an optimization function that is a Stochastic Gradient Descent (SGD) with Nesterov momentum\n",
    "# Learning Rate: 0.001\n",
    "# Nesterov Momentum: 0.9\n",
    "optimizer = optim.SGD(cnn.parameters(), lr=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Additional comments:\n",
    "# I tested out a higher learning rate (0.01), but that led to a consistent reduction in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAINING CELL\n",
    "## Trains the convolutional neural network using the framework prepared thus far\n",
    "\n",
    "# Loop over our data iterator, and feed the inputs to the network and optimize\n",
    "\n",
    "# For-loop that iterates over the entire training set 5 times/epochs\n",
    "# 'epoch' increments 0 to 4\n",
    "for epoch in range(5):                                         \n",
    "    \n",
    "    running_loss = 0.0                                 # Sets loss to 0.0 at the start of every epoch\n",
    "    \n",
    "    # Nested for-loop that iterates over the training set in batches of 4\n",
    "    # Feeds inputs to the network, computes loss, backprops, and optimizes\n",
    "    # 'batch' increments 0 to 6250 (1 every 1000 batches)\n",
    "    for batch, data in enumerate(trainingloader, 0): \n",
    "       \n",
    "        inputs, labels = data                          # Separates the batch into the inputs and their correct labels\n",
    "        \n",
    "        optimizer.zero_grad()                          # Zeroes the parameter gradients to prevent accumulation\n",
    "        \n",
    "        outputs = cnn(inputs)                          # Feeds image inputs into the network (forward propagation)\n",
    "        \n",
    "        loss = loss_function(outputs, labels)          # Computes the loss between the outputs and target labels\n",
    "        \n",
    "        loss.backward()                                # Backpropagation\n",
    "        \n",
    "        optimizer.step()                               # Updates the SGD parameters\n",
    "        \n",
    "        running_loss += loss.item()                    # Adds to the total loss for the current 1000 batches\n",
    "        \n",
    "        if batch % 2000 == 1999:                       # Reports the average loss for every 1000 batches\n",
    "            print('Epoch[%d] Batch[%5d] Loss[%.3f]' %\n",
    "                  (epoch + 1, batch + 1, running_loss / 2000))\n",
    "            running_loss = 0.0                         # Sets loss back to 0.0 after reporting\n",
    "            \n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "# Additional comments:\n",
    "# This training session takes 15-20 minutes to complete on my computer.\n",
    "# I am currently running Mojave 10.14 on my MacBook, so I am unfortunatey unable to run any processes \n",
    "# in Python on my NVIDIA GPU through CUDA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TESTING CELL 1\n",
    "## This is an simple, repeatable test to see how well the trained network can classify a batch of test images\n",
    "\n",
    "# Defines a function that converts images back from tensors into their original PIL Image form\n",
    "def imshow(img):\n",
    "    \n",
    "    img = torchvision.utils.make_grid(img)       # Arranges images into a grid\n",
    "    img[0] = img[0] * 0.2023 + 0.4914            # Unnormalizes the images using the same means and standard deviations \n",
    "    img[1] = img[1] * 0.1994 + 0.4822\n",
    "    img[2] = img[2] * 0.2010 + 0.4465\n",
    "    npimg = img.numpy()                          # Converts tensor values to numpy values\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))   # Reshapes image data back from (C x H x W) to (H x W x C)\n",
    "    plt.show()                                   # Graph the images\n",
    "\n",
    "\n",
    "# Iterates once through the test loader to select a batch of 4 random test images\n",
    "dataiter = iter(testloader)                      \n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Graphs the 4 test images\n",
    "imshow(images)                                   \n",
    "\n",
    "# Prints the actual class of each test image\n",
    "# 'j' here refers to the indices 0-4 of the batch of 4 images\n",
    "print('Actual: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "# Feeds the 4 test images into the network\n",
    "outputs = cnn(images)\n",
    "\n",
    "# Defines 'predicted' as a tensor consisting of the indices of the predicted images in the current batch\n",
    "# torch.max also returns the tensor of the probability values, but that is discarded by the blank identifier \n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Prints the network's predicted class for each image\n",
    "# 'j' here refers to the indices 0-4 in the list of 4 predicted labels\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TESTING CELL 2: Overall Network Accuracy\n",
    "## This test calculates the trained network's overall accuracy at matching images across the entire CIFAR-10 test set\n",
    "# I have consistently achieved values in the range of 70-72%\n",
    "\n",
    "# Sets these two variables at zero to start\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# This is a PyTorch-specific wrapper that prevents PyTorch objects from using memory to keep track of their history\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # For-loop that iterates through the entire test set of 10000 images, a batch of 4 at a time\n",
    "    for data in testloader:\n",
    "        \n",
    "        # Separates the test set into the images and their correct labels\n",
    "        images, labels = data\n",
    "        \n",
    "        # Feeds every test image into the network\n",
    "        outputs = cnn(images)\n",
    "        \n",
    "        # Defines 'predicted' as a tensor consisting of the indices of the predicted labels in the current batch\n",
    "        # torch.max also returns the tensor of the probability values, but that is discarded by the blank identifier\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Adds up the number of labels, eventually to 10000\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        # Adds up the number of labels correctly predicted by the network\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Computes the percentage of correct predictions made by the network\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TESTING CELL 3: Network Accuracy Per CIFAR-10 Class\n",
    "## This test calculates the trained network's accuracy at matching images in each class in the CIFAR-10 test set\n",
    "\n",
    "# Defines two 10-item lists, and sets all items to 0. to start\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "# This is a PyTorch-specific wrapper that prevents PyTorch objects from using memory to keep track of their history\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # For-loop that iterates through the entire test set of 10000 images\n",
    "    for data in testloader:\n",
    "        \n",
    "        # Separates the test set into the images and their correct labels\n",
    "        images, labels = data\n",
    "        \n",
    "        # Feeds every test image into the network\n",
    "        outputs = cnn(images)\n",
    "        \n",
    "        # Defines 'predicted' as a tensor consisting of the indices of the predicted labels in the current batch\n",
    "        # torch.max also returns the tensor of the probability values, but that is discarded by the blank identifier\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        \n",
    "        # Defines a tensor of conditions (True or False) for the predictions in the current batch\n",
    "        c = (predicted == labels).squeeze()\n",
    "        \n",
    "        # Nested for-loop that iterates over each batch of 4 test images\n",
    "        for i in range (4):\n",
    "            \n",
    "            # Returns the correctly numbered label at each position in the batch\n",
    "            label = labels[i]\n",
    "            # When a class label 0-9 is returned by 'label', and the prediction for that label in 'c' matches,\n",
    "            # 1 is added to the value at that index in class_correct\n",
    "            class_correct[label] += c[i].item()\n",
    "            # When a class label 0-9 is returned by 'label', 1 is added to the value at that index in class_total\n",
    "            class_total[label] += 1\n",
    "\n",
    "# For-loop that prints the results for each class, indexed 0 to 9            \n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
